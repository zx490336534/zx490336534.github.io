<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="爬虫," />





  <link rel="alternate" href="/atom.xml" title="测试游记" type="application/atom+xml" />






<meta name="description" content="scrapy结合selenium进行动态加载页面内容爬取动态页面与静态页面比较常见的页面形式可以分为两种：  静态页面 动态页面">
<meta property="og:type" content="article">
<meta property="og:title" content="scrapy结合selenium进行动态加载页面内容爬取">
<meta property="og:url" content="http://zx490336534.github.io/article/5cbdb45.html">
<meta property="og:site_name" content="测试游记">
<meta property="og:description" content="scrapy结合selenium进行动态加载页面内容爬取动态页面与静态页面比较常见的页面形式可以分为两种：  静态页面 动态页面">
<meta property="og:locale">
<meta property="og:image" content="http://zx490336534.github.io/article/%E7%99%BE%E5%BA%A6%E6%BA%90%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="http://zx490336534.github.io/article/%E6%9F%A5%E7%9C%8B%E7%BD%91%E9%A1%B5%E6%BA%90%E4%BB%A3%E7%A0%81.png">
<meta property="og:image" content="http://zx490336534.github.io/article/%E5%8C%97%E4%BA%AC%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E6%8C%87%E6%95%B0.png">
<meta property="og:image" content="http://zx490336534.github.io/article/%E6%A3%80%E6%9F%A5.png">
<meta property="og:image" content="http://zx490336534.github.io/article/xpath.png">
<meta property="og:image" content="http://zx490336534.github.io/article/%E7%BB%93%E6%9E%9C.png">
<meta property="article:published_time" content="2018-09-27T00:43:00.000Z">
<meta property="article:modified_time" content="2021-04-22T14:34:11.407Z">
<meta property="article:author" content="测试游记">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://zx490336534.github.io/article/%E7%99%BE%E5%BA%A6%E6%BA%90%E4%BB%A3%E7%A0%81.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zx490336534.github.io/article/5cbdb45.html"/>





  <title>scrapy结合selenium进行动态加载页面内容爬取 | 测试游记</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?41fc030db57d5570dd22f78997dc4a7e";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">测试游记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://zx490336534.github.io/article/5cbdb45.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="测试游记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">scrapy结合selenium进行动态加载页面内容爬取</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-27T08:43:00+08:00">
                2018-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%88%AC%E8%99%AB/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/article/5cbdb45.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="article/5cbdb45.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="scrapy结合selenium进行动态加载页面内容爬取"><a href="#scrapy结合selenium进行动态加载页面内容爬取" class="headerlink" title="scrapy结合selenium进行动态加载页面内容爬取"></a>scrapy结合selenium进行动态加载页面内容爬取</h1><h2 id="动态页面与静态页面"><a href="#动态页面与静态页面" class="headerlink" title="动态页面与静态页面"></a>动态页面与静态页面</h2><p>比较常见的页面形式可以分为两种：</p>
<ul>
<li>静态页面</li>
<li>动态页面<span id="more"></span>
<a target="_blank" rel="noopener" href="https://www.cnblogs.com/bluesungz/p/5955170.html">静态页面和动态页面的区别</a></li>
</ul>
<p>使用<code>requests</code>进行数据获取的时候一般使用的是<code>respond.text</code>来获取网页源码，然后通过正则表达式提取出需要的内容。</p>
<p>例如：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">print(response.text.encode(<span class="string">'raw_unicode_escape'</span>).decode())</span><br></pre></td></tr></tbody></table></figure>

<p><img src="%E7%99%BE%E5%BA%A6%E6%BA%90%E4%BB%A3%E7%A0%81.png" alt="百度源代码"></p>
<p>但是动态页面使用上述操作后发现，获取到的内容与实际相差很大。</p>
<p>例如我们打开如下页面：</p>
<p><code>https://www.aqistudy.cn/historydata/monthdata.php?city=北京</code></p>
<p>右键选择<code>查看网页源代码</code></p>
<p><img src="%E6%9F%A5%E7%9C%8B%E7%BD%91%E9%A1%B5%E6%BA%90%E4%BB%A3%E7%A0%81.png" alt="查看网页源代码"></p>
<p>在网页源代码中查找页面中存在的一个数据：2014-02的PM10为155。</p>
<p><img src="%E5%8C%97%E4%BA%AC%E7%A9%BA%E6%B0%94%E8%B4%A8%E9%87%8F%E6%8C%87%E6%95%B0.png" alt="北京空气质量指数"></p>
<p>这时打开F12查看<code>Elements</code> 可以看到<code>155</code>在元素中有显示</p>
<p><img src="%E6%A3%80%E6%9F%A5.png" alt="检查"></p>
<p>综上基本可以明白静态页面和动态页面的区别了。</p>
<p>有两种方式可以获取动态页面的内容：</p>
<ul>
<li>破解JS，实现动态渲染</li>
<li>使用浏览器模拟操作，等待模拟浏览器完成页面渲染</li>
</ul>
<p>由于第一个比较困难所以选择方法二</p>
<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>获取各个城市近年来每天的空气质量</p>
<ul>
<li>日期</li>
<li>城市</li>
<li>空气质量指数</li>
<li>空气质量等级</li>
<li>pm2.5</li>
<li>pm10</li>
<li>so2</li>
<li>co</li>
<li>no2</li>
<li>o3</li>
</ul>
<h2 id="使用scrapy"><a href="#使用scrapy" class="headerlink" title="使用scrapy"></a>使用scrapy</h2><p>scrapy操作的基本流程如下：</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.创建项目：scrapy startproject 项目名称</span><br><span class="line">2.新建爬虫：scrapy genspider 爬虫文件名 爬虫基础域名</span><br><span class="line">3.编写item</span><br><span class="line">4.spider最后return item</span><br><span class="line">5.在setting中修改pipeline配置</span><br><span class="line">6.在对应pipeline中进行数据持久化操作</span><br></pre></td></tr></tbody></table></figure>

<h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>打开命令行，输入<code>scrapy startproject air_history</code> ,创建一个名为<code>air_history</code>的scrapy项目</p>
<p>进入该文件夹，输入<code>scrapy genspider area_spider "aqistudy.cn"</code>,可以发现在spiders文件夹下多了一个名为<code>area_spider</code>的py文件</p>
<p>文件目录结构大概如下：</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── air_history</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   │   ├── __init__.cpython-36.pyc</span><br><span class="line">│   │   └── settings.cpython-36.pyc</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── area_spider.py</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── __pycache__</span><br><span class="line">│           └── __init__.cpython-36.pyc</span><br><span class="line">└── scrapy.cfg</span><br></pre></td></tr></tbody></table></figure>

<h3 id="编写item"><a href="#编写item" class="headerlink" title="编写item"></a>编写item</h3><p>根据需求编写item如下,spider最后<code>return item</code>，把值传递给它</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AirHistoryItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    data = scrapy.Field() <span class="comment">#日期</span></span><br><span class="line">    city = scrapy.Field() <span class="comment">#城市</span></span><br><span class="line">    aqi = scrapy.Field() <span class="comment">#空气质量指数</span></span><br><span class="line">    level = scrapy.Field() <span class="comment">#空气质量等级</span></span><br><span class="line">    pm2_5 = scrapy.Field() <span class="comment">#pm2.5</span></span><br><span class="line">    pm10 = scrapy.Field() <span class="comment">#pm10</span></span><br><span class="line">    so2 = scrapy.Field() <span class="comment">#so2</span></span><br><span class="line">    co = scrapy.Field() <span class="comment">#co</span></span><br><span class="line">    no2 = scrapy.Field() <span class="comment">#no2</span></span><br><span class="line">    o3 = scrapy.Field()  <span class="comment">#o3</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="编写爬虫"><a href="#编写爬虫" class="headerlink" title="编写爬虫"></a>编写爬虫</h3><p>首先可以得知首页是<code>https://www.aqistudy.cn/historydata/</code></p>
<p>所以将它赋值给一个名为<code>base_url</code>的变量，方便后续使用</p>
<p>自动创建的爬出中携带了爬虫的名字，这个name在启动爬虫的时候需要用到，现在暂时用不到</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'area_spider'</span></span><br><span class="line">allowed_domains = [<span class="string">'aqistudy.cn'</span>]  <span class="comment"># 爬取的域名，不会超出这个顶级域名</span></span><br><span class="line">base_url = <span class="string">"https://www.aqistudy.cn/historydata/"</span></span><br><span class="line">start_urls = [base_url]</span><br></pre></td></tr></tbody></table></figure>

<p>####城市信息</p>
<p>进入首页之后可以看到一大批的城市信息，所以我们第一步就是获取有哪些城市</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">	print(<span class="string">'爬取城市信息....'</span>)</span><br><span class="line">	url_list = response.xpath(<span class="string">"//div[@class='all']/div[@class='bottom']/ul/div[2]/li/a/@href"</span>).extract()  <span class="comment"># 全部链接</span></span><br><span class="line">	city_list = response.xpath(<span class="string">"//div[@class='all']/div[@class='bottom']/ul/div[2]/li/a/text()"</span>).extract()  <span class="comment"># 城市名称</span></span><br><span class="line">	<span class="keyword">for</span> url, city <span class="keyword">in</span> <span class="built_in">zip</span>(url_list, city_list):</span><br><span class="line">		<span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse_month, meta={<span class="string">'city'</span>: city})</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>使用插件<code>XPath Helper</code>可以对xpath进行一个测试，看看定位的内容是否正确</p>
<p><img src="xpath.png" alt="xpath"></p>
<p>随意点击一个地区可以发现url变为<code>https://www.aqistudy.cn/historydata/monthdata.php?city=北京</code></p>
<p>所以<code>url_list</code>获取到的是需要进行拼接的内容<code>monthdata.php?city=城市名称</code></p>
<p><code>city_list</code>的最后部分是<code>text()</code>所以它拿到的是具体的文本信息</p>
<p>将获取到的url_list和city_list逐个传递给<code>scrapy.Request</code>其中url是需要继续爬取的页面地址，city是item中需要的内容，所以将item暂时存放在meta中传递给下个回调函数<code>self.parse_month</code></p>
<h3 id="月份信息"><a href="#月份信息" class="headerlink" title="月份信息"></a>月份信息</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_month</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    print(<span class="string">'爬取{}月份...'</span>.<span class="built_in">format</span>(response.meta[<span class="string">'city'</span>]))</span><br><span class="line">    url_list = response.xpath(<span class="string">'//tbody/tr/td/a/@href'</span>).extract()</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">        url = self.base_url + url</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse_day, meta={<span class="string">'city'</span>: response.meta[<span class="string">'city'</span>]})</span><br></pre></td></tr></tbody></table></figure>

<p>此步操作获取了每个城市的全部月份信息，并拿到了每个月份的url地址。把上面传递下来的city继续向下传递</p>
<h4 id="最终数据"><a href="#最终数据" class="headerlink" title="最终数据"></a>最终数据</h4><p>获取到最终的URL之后，把item实例化，然后完善item字典并返回item</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_day</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    print(<span class="string">'爬取最终数据...'</span>)</span><br><span class="line">    item = AirHistoryItem()</span><br><span class="line">    node_list = response.xpath(<span class="string">'//tr'</span>)</span><br><span class="line">    node_list.pop(<span class="number">0</span>)  <span class="comment"># 去除第一行标题栏</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> node_list:</span><br><span class="line">        item[<span class="string">'data'</span>] = node.xpath(<span class="string">'./td[1]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'city'</span>] = response.meta[<span class="string">'city'</span>]</span><br><span class="line">        item[<span class="string">'aqi'</span>] = node.xpath(<span class="string">'./td[2]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'level'</span>] = node.xpath(<span class="string">'./td[3]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'pm2_5'</span>] = node.xpath(<span class="string">'./td[4]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'pm10'</span>] = node.xpath(<span class="string">'./td[5]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'so2'</span>] = node.xpath(<span class="string">'./td[6]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'co'</span>] = node.xpath(<span class="string">'./td[7]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'no2'</span>] = node.xpath(<span class="string">'./td[8]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'o3'</span>] = node.xpath(<span class="string">'./td[9]/text()'</span>).extract_first()</span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></tbody></table></figure>

<h3 id="使用中间件实现selenium操作"><a href="#使用中间件实现selenium操作" class="headerlink" title="使用中间件实现selenium操作"></a>使用中间件实现selenium操作</h3><p>打开中间件文件<code>middlewares.py</code></p>
<p>由于我是在服务器上进行爬取，所以我选择使用谷歌的无界面浏览器<code>chrome-headless</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"></span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>)  <span class="comment"># 使用无头谷歌浏览器模式</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--disable-gpu'</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">'--no-sandbox'</span>)</span><br><span class="line"><span class="comment"># 指定谷歌浏览器路径</span></span><br><span class="line">webdriver.Chrome(chrome_options=chrome_options,executable_path=<span class="string">'/root/zx/spider/driver/chromedriver'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>然后进行页面渲染后的源码获取</p>
<p><code>request.url</code>是传递到中间件的url，由于首页是静态页面，所以首页不进行selenium操作</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> request.url != <span class="string">'https://www.aqistudy.cn/historydata/'</span>:</span><br><span class="line">    self.driver.get(request.url)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    html = self.driver.page_source</span><br><span class="line">    self.driver.quit()</span><br><span class="line">    <span class="keyword">return</span> scrapy.http.HtmlResponse(url=request.url, body=html.encode(<span class="string">'utf-8'</span>), encoding=<span class="string">'utf-8'</span>,request=request)</span><br></pre></td></tr></tbody></table></figure>

<p>后续的操作也很简单，最后将获取到的内容正确编码后返回给爬虫的下一步</p>
<h3 id="middlewares全部代码"><a href="#middlewares全部代码" class="headerlink" title="middlewares全部代码"></a>middlewares全部代码</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AreaSpiderMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        chrome_options = Options()</span><br><span class="line">        chrome_options.add_argument(<span class="string">'--headless'</span>)  <span class="comment"># 使用无头谷歌浏览器模式</span></span><br><span class="line">        chrome_options.add_argument(<span class="string">'--disable-gpu'</span>)</span><br><span class="line">        chrome_options.add_argument(<span class="string">'--no-sandbox'</span>)</span><br><span class="line">        <span class="comment"># 指定谷歌浏览器路径</span></span><br><span class="line">        <span class="comment"># chrome_options.binary_location = '/root/zx/spider/driver/chromedriver'</span></span><br><span class="line">        self.driver = webdriver.Chrome(chrome_options=chrome_options,executable_path=<span class="string">'/root/zx/spider/driver/chromedriver'</span>)</span><br><span class="line">        <span class="keyword">if</span> request.url != <span class="string">'https://www.aqistudy.cn/historydata/'</span>:</span><br><span class="line">            self.driver.get(request.url)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            html = self.driver.page_source</span><br><span class="line">            self.driver.quit()</span><br><span class="line">            <span class="keyword">return</span> scrapy.http.HtmlResponse(url=request.url, body=html.encode(<span class="string">'utf-8'</span>), encoding=<span class="string">'utf-8'</span>,</span><br><span class="line">                                            request=request)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="使用下载器保存item内容"><a href="#使用下载器保存item内容" class="headerlink" title="使用下载器保存item内容"></a>使用下载器保存item内容</h3><p>修改<code>pipelines.py</code>进行文件的存储</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AirHistoryPipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">'area.json'</span>, <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        context = json.dumps(<span class="built_in">dict</span>(item),ensure_ascii=<span class="literal">False</span>) + <span class="string">'\n'</span></span><br><span class="line">        self.file.write(context)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></tbody></table></figure>

<h3 id="修改settings文件使中间件，下载器生效"><a href="#修改settings文件使中间件，下载器生效" class="headerlink" title="修改settings文件使中间件，下载器生效"></a>修改settings文件使中间件，下载器生效</h3><p>打开<code>settings.py</code>文件</p>
<p>修改以下内容：<code>DOWNLOADER_MIDDLEWARES</code>使刚才写的middlewares中间件中的类,<code>ITEM_PIPELINES</code>是pipelines中的类</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">'air_history'</span></span><br><span class="line">SPIDER_MODULES = [<span class="string">'air_history.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'air_history.spiders'</span></span><br><span class="line"></span><br><span class="line">USER_AGENT = <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'</span></span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = {</span><br><span class="line">   <span class="string">'air_history.middlewares.AreaSpiderMiddleware'</span>: <span class="number">543</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = {</span><br><span class="line">   <span class="string">'air_history.pipelines.AirHistoryPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p><code>使用scrapy crawl area_spider就可以运行爬虫</code></p>
<p><img src="%E7%BB%93%E6%9E%9C.png" alt="结果"></p>
<h4 id="spider全部代码"><a href="#spider全部代码" class="headerlink" title="spider全部代码"></a>spider全部代码</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> air_history.items <span class="keyword">import</span> AirHistoryItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AreaSpiderSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">'area_spider'</span></span><br><span class="line">    allowed_domains = [<span class="string">'aqistudy.cn'</span>]  <span class="comment"># 爬取的域名，不会超出这个顶级域名</span></span><br><span class="line">    base_url = <span class="string">"https://www.aqistudy.cn/historydata/"</span></span><br><span class="line">    start_urls = [base_url]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        print(<span class="string">'爬取城市信息....'</span>)</span><br><span class="line">        url_list = response.xpath(<span class="string">"//div[@class='all']/div[@class='bottom']/ul/div[2]/li/a/@href"</span>).extract()  <span class="comment"># 全部链接</span></span><br><span class="line">        city_list = response.xpath(<span class="string">"//div[@class='all']/div[@class='bottom']/ul/div[2]/li/a/text()"</span>).extract()  <span class="comment"># 城市名称</span></span><br><span class="line">        <span class="keyword">for</span> url, city <span class="keyword">in</span> <span class="built_in">zip</span>(url_list, city_list):</span><br><span class="line">            url = self.base_url + url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse_month, meta={<span class="string">'city'</span>: city})</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_month</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        print(<span class="string">'爬取{}月份...'</span>.<span class="built_in">format</span>(response.meta[<span class="string">'city'</span>]))</span><br><span class="line">        url_list = response.xpath(<span class="string">'//tbody/tr/td/a/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">            url = self.base_url + url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse_day, meta={<span class="string">'city'</span>: response.meta[<span class="string">'city'</span>]})</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_day</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        print(<span class="string">'爬取最终数据...'</span>)</span><br><span class="line">        item = AirHistoryItem()</span><br><span class="line">        node_list = response.xpath(<span class="string">'//tr'</span>)</span><br><span class="line">        node_list.pop(<span class="number">0</span>)  <span class="comment"># 去除第一行标题栏</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> node_list:</span><br><span class="line">            item[<span class="string">'data'</span>] = node.xpath(<span class="string">'./td[1]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'city'</span>] = response.meta[<span class="string">'city'</span>]</span><br><span class="line">            item[<span class="string">'aqi'</span>] = node.xpath(<span class="string">'./td[2]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'level'</span>] = node.xpath(<span class="string">'./td[3]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'pm2_5'</span>] = node.xpath(<span class="string">'./td[4]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'pm10'</span>] = node.xpath(<span class="string">'./td[5]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'so2'</span>] = node.xpath(<span class="string">'./td[6]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'co'</span>] = node.xpath(<span class="string">'./td[7]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'no2'</span>] = node.xpath(<span class="string">'./td[8]/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'o3'</span>] = node.xpath(<span class="string">'./td[9]/text()'</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></tbody></table></figure>


      
    </div>
    
    
    

    
      <div>
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/images/wechat-qcode.jpg" alt=" wechat" style="width: 200px; max-width: 100%;"/>
    <div>欢迎您扫一扫上面的微信公众号，订阅我的博客！</div>
</div>

      </div>
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt=" 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt=" 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"># 爬虫</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/article/b44aa9e7.html" rel="next" title="Response Headers的转换">
                <i class="fa fa-chevron-left"></i> Response Headers的转换
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/article/61ec1818.html" rel="prev" title="爬取抖音的回复信息">
                爬取抖音的回复信息 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives%7C%7C%20archive">
              
                  <span class="site-state-item-count">164</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zx490336534" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/zhong-xin-97-8" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-angellist"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://testingpai.com/" title="测试派" target="_blank">测试派</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://testerhome.com/" title="TesterHome" target="_blank">TesterHome</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://dongfanger.gitee.io/blog/index.html" title="自动化代码美学" target="_blank">自动化代码美学</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#scrapy%E7%BB%93%E5%90%88selenium%E8%BF%9B%E8%A1%8C%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E9%A1%B5%E9%9D%A2%E5%86%85%E5%AE%B9%E7%88%AC%E5%8F%96"><span class="nav-number">1.</span> <span class="nav-text">scrapy结合selenium进行动态加载页面内容爬取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E9%A1%B5%E9%9D%A2%E4%B8%8E%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2"><span class="nav-number">1.1.</span> <span class="nav-text">动态页面与静态页面</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span class="nav-number">1.2.</span> <span class="nav-text">需求分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8scrapy"><span class="nav-number">1.3.</span> <span class="nav-text">使用scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA"><span class="nav-number">1.3.1.</span> <span class="nav-text">创建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E5%86%99item"><span class="nav-number">1.3.2.</span> <span class="nav-text">编写item</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E5%86%99%E7%88%AC%E8%99%AB"><span class="nav-number">1.3.3.</span> <span class="nav-text">编写爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%88%E4%BB%BD%E4%BF%A1%E6%81%AF"><span class="nav-number">1.3.4.</span> <span class="nav-text">月份信息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E7%BB%88%E6%95%B0%E6%8D%AE"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">最终数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%AE%9E%E7%8E%B0selenium%E6%93%8D%E4%BD%9C"><span class="nav-number">1.3.5.</span> <span class="nav-text">使用中间件实现selenium操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#middlewares%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="nav-number">1.3.6.</span> <span class="nav-text">middlewares全部代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E4%B8%8B%E8%BD%BD%E5%99%A8%E4%BF%9D%E5%AD%98item%E5%86%85%E5%AE%B9"><span class="nav-number">1.3.7.</span> <span class="nav-text">使用下载器保存item内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9settings%E6%96%87%E4%BB%B6%E4%BD%BF%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%8C%E4%B8%8B%E8%BD%BD%E5%99%A8%E7%94%9F%E6%95%88"><span class="nav-number">1.3.8.</span> <span class="nav-text">修改settings文件使中间件，下载器生效</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C"><span class="nav-number">1.4.</span> <span class="nav-text">运行</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#spider%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="nav-number">1.4.0.1.</span> <span class="nav-text">spider全部代码</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">测试游记</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://zx490336534.github.io/article/5cbdb45.html';
          this.page.identifier = 'article/5cbdb45.html';
          this.page.title = 'scrapy结合selenium进行动态加载页面内容爬取';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
